{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12807122,"sourceType":"datasetVersion","datasetId":8098022},{"sourceId":529441,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":414152,"modelId":431891}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nos.environ[\"TF_ENABLE_LAYOUT_OPTIMIZER\"] = \"0\"\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.metrics import AUC, Precision, Recall\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndef __len__(self):\n    return len(self.indices) // self.batch_size \nstrategy = tf.distribute.MirroredStrategy()\nprint(\"Number of devices:\", strategy.num_replicas_in_sync)\nprint(\"Done\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Dual-GPU ConvLSTM Training (Kaggle T4 x2)\n# =========================\n\n# --- MUST be set before importing TensorFlow ---\nimport os\nos.environ[\"TF_ENABLE_LAYOUT_OPTIMIZER\"] = \"0\"   # avoid ConvLSTM graph layout cycle\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"         # quieter logs\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.metrics import AUC\n\n# -------------------------\n# Config\n# -------------------------\nTIME_STEPS = 5\nHEIGHT = 224\nWIDTH  = 168\nBANDS  = 6               # physical bands (before mask)\nCHANNELS = 7             # 6 bands + 1 mask\nBATCH_SIZE = 8           # effective global batch = BATCH_SIZE; each GPU gets BATCH_SIZE/num_gpus\nEPOCHS = 50\nLR = 5e-5\n\nX_PATH = \"/kaggle/input/cyclone-features-and-labels/Features_data.npy\"\nY_PATH = \"/kaggle/input/cyclone-features-and-labels/Label_data.npy\"\n\nOUT_DIR = \"/kaggle/working\"\nMODEL_PATH = os.path.join(OUT_DIR, \"best_convlstm.keras\")\nNORM_PATH  = os.path.join(OUT_DIR, \"norm_stats.npz\")\n\n# -------------------------\n# Load arrays\n# -------------------------\nX = np.load(X_PATH, mmap_mode=\"r\")  # (num_days, 6, H, W)\nY = np.load(Y_PATH, mmap_mode=\"r\")  # (num_days,)\nnum_days = X.shape[0]\nprint(\"X:\", X.shape, \"Y:\", Y.shape)\n\n# -------------------------\n# Build sequence indices & labels (label = last day of each window)\n# -------------------------\nseq_start_idxs = np.arange(0, num_days - TIME_STEPS + 1)\nseq_labels = Y[TIME_STEPS-1:]   # aligns with window end\n\n# Stratified train/val split at SEQUENCE level (prevents leakage)\ntrain_idx, val_idx, y_train_seq, y_val_seq = train_test_split(\n    seq_start_idxs, seq_labels, test_size=0.2, random_state=42, stratify=seq_labels\n)\nprint(f\"Train sequences: {len(train_idx)} | Val sequences: {len(val_idx)}\")\nprint(f\"Positives in train: {int(y_train_seq.sum())} | Positives in val: {int(y_val_seq.sum())}\")\n\n# -------------------------\n# Compute per-band normalization stats on TRAINING DAYS ONLY\n# -------------------------\ntrain_day_mask = np.zeros(num_days, dtype=bool)\nfor s in train_idx:\n    train_day_mask[s:s+TIME_STEPS] = True\n\ntrain_days = X[train_day_mask]  # (N_train_days, 6, H, W)\nband_means = np.nanmean(train_days, axis=(0,2,3)).astype(np.float32)            # (6,)\nband_stds  = np.nanstd(train_days, axis=(0,2,3)).astype(np.float32)\nband_stds[band_stds < 1e-3] = 1.0\nnp.savez(NORM_PATH, band_means=band_means, band_stds=band_stds)\nprint(\"Saved normalization stats ->\", NORM_PATH)\nprint(\"Band means:\", band_means)\nprint(\"Band stds :\", band_stds)\n\n# -------------------------\n# Data Generator (sequence level) - multi-GPU safe\n# -------------------------\nclass SeqDataGenerator(Sequence):\n    \"\"\"\n    Generates ConvLSTM sequences with:\n      - NaN -> 0 (safe replace)\n      - z-score per band (using provided means/stds; computed from train only)\n      - mask channel (from first band: valid=1, NaN=0)\n      - output: (batch, TIME_STEPS, H, W, CHANNELS)\n    \"\"\"\n    def __init__(self, X, Y, seq_starts, time_steps, band_means, band_stds,\n                 batch_size=8, shuffle=True, drop_remainder=True):\n        self.X = X\n        self.Y = Y\n        self.seq_starts = np.array(seq_starts, dtype=np.int64)\n        self.time_steps = time_steps\n        self.band_means = band_means.astype(np.float32)\n        self.band_stds  = band_stds.astype(np.float32)\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.drop_remainder = drop_remainder\n        self.indexes = np.arange(len(self.seq_starts))\n        self.on_epoch_end()\n\n    def __len__(self):\n        if self.drop_remainder:\n            return len(self.indexes) // self.batch_size\n        return int(np.ceil(len(self.indexes) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_ids = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n        # drop short last batch (important for multi-GPU all-reduce)\n        if self.drop_remainder and len(batch_ids) < self.batch_size:\n            batch_ids = self.indexes[-self.batch_size:]\n\n        X_batch, Y_batch = [], []\n        for bi in batch_ids:\n            s = self.seq_starts[bi]\n            # seq_x: (T, 6, H, W)\n            seq_x = self.X[s:s+self.time_steps].astype(np.float32)\n\n            # mask from FIRST band (True where not NaN)\n            m = ~np.isnan(seq_x[:, 0, :, :])                   # (T, H, W) bool\n            m = m.astype(np.float32)[:, None, :, :]            # (T, 1, H, W)\n\n            # replace NaNs with 0 (safe)\n            seq_x = np.nan_to_num(seq_x, nan=0.0, posinf=0.0, neginf=0.0)\n\n            # z-score per band (broadcast across T,H,W)\n            seq_x = (seq_x - self.band_means[None, :, None, None]) / self.band_stds[None, :, None, None]\n\n            # concat mask\n            seq_x = np.concatenate([seq_x, m], axis=1)         # (T, 7, H, W)\n\n            # to (T, H, W, C)\n            seq_x = np.transpose(seq_x, (0, 2, 3, 1)).astype(np.float32)\n\n            X_batch.append(seq_x)\n            Y_batch.append(self.Y[s + self.time_steps - 1])\n\n        Xb = np.stack(X_batch, axis=0)                         # (B, T, H, W, C)\n        Yb = np.array(Y_batch, dtype=np.float32)               # (B,)\n        # safety checks (catch NaNs before the model)\n        if not np.isfinite(Xb).all():\n            raise ValueError(\"Non-finite values in X batch\")\n        if not np.isfinite(Yb).all():\n            raise ValueError(\"Non-finite values in Y batch\")\n        return Xb, Yb\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n# -------------------------\n# Build Generators\n# -------------------------\ntrain_gen = SeqDataGenerator(X, Y, train_idx, TIME_STEPS, band_means, band_stds,\n                             batch_size=BATCH_SIZE, shuffle=True,  drop_remainder=True)\nval_gen   = SeqDataGenerator(X, Y, val_idx,   TIME_STEPS, band_means, band_stds,\n                             batch_size=BATCH_SIZE, shuffle=False, drop_remainder=True)\n\n# -------------------------\n# Class Weights (sequence-level) — optional clipping to avoid instability\n# -------------------------\ncw = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_seq), y=y_train_seq)\nclass_weights = dict(enumerate(np.minimum(cw, 5.0)))   # clip huge weights\nprint(\"Class weights (sequence-level):\", class_weights)\n\n# -------------------------\n# Multi-GPU Strategy\n# -------------------------\nstrategy = tf.distribute.OneDeviceStrategy(\"GPU:0\")  # uses all visible GPUs\nprint(\"GPUs in sync:\", strategy.num_replicas_in_sync)\n\nwith strategy.scope():\n    model = Sequential([\n        ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n                   return_sequences=True, input_shape=(TIME_STEPS, HEIGHT, WIDTH, CHANNELS)),\n        BatchNormalization(),\n\n        ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\",\n                   return_sequences=False),\n        BatchNormalization(),\n\n        GlobalAveragePooling2D(),\n        Dense(128, activation=\"relu\"),\n        Dropout(0.3),\n        Dense(1, activation=\"sigmoid\")\n    ])\n\n    optimizer = Adam(learning_rate=LR, clipnorm=1.0) # grad clipping helps stability\n    model.compile(\n        optimizer=optimizer,\n        loss=\"binary_crossentropy\",\n        metrics=[\n            \"accuracy\",\n            AUC(curve=\"ROC\", name=\"auc\")\n        ]\n    )\n\nmodel.summary()\n\n# -------------------------\n# Callbacks (EarlyStopping + Best Model)\n# -------------------------\ncallbacks = [\n    EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=8, restore_best_weights=True, verbose=1),\n    ModelCheckpoint(MODEL_PATH, monitor=\"val_auc\", mode=\"max\", save_best_only=True, verbose=1)\n]\n\n# -------------------------\n# Train\n# -------------------------\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    class_weight=class_weights,\n    callbacks=callbacks,\n    verbose=1\n)\n\nprint(\"Best model saved ->\", MODEL_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T03:32:23.125808Z","iopub.execute_input":"2025-08-20T03:32:23.126054Z"}},"outputs":[{"name":"stdout","text":"X: (5479, 6, 224, 168) Y: (5479,)\nTrain sequences: 4380 | Val sequences: 1095\nPositives in train: 345 | Positives in val: 86\nSaved normalization stats -> /kaggle/working/norm_stats.npz\nBand means: [ 2.8866348e+03  8.2428616e-01  6.8315333e-01 -1.4377959e-02\n  9.9217078e+04  1.7229028e-02]\nBand stds : [1.20197723e+02 3.43794990e+00 3.12991667e+00 1.15119345e-01\n 3.58106348e+03 3.90403694e-03]\nClass weights (sequence-level): {0: 0.5427509293680297, 1: 5.0}\nGPUs in sync: 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv_lstm2d (\u001b[38;5;33mConvLSTM2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m168\u001b[0m,    │        \u001b[38;5;34m45,056\u001b[0m │\n│                                 │ \u001b[38;5;34m32\u001b[0m)                    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m168\u001b[0m,    │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m32\u001b[0m)                    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv_lstm2d_1 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m168\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m168\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv_lstm2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">45,056</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>,    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv_lstm2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m123,521\u001b[0m (482.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,521</span> (482.50 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,393\u001b[0m (482.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,393</span> (482.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1755660845.817249      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_248/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/mul_1' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_248/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/add_7', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_248/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/Sigmoid_1' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_248/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/mul', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_248/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/Sigmoid_2' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_248/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/mul_2', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/zeros_1_switch/_332-0-TransposeNHWCToNCHW-LayoutOptimizer' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/zeros_1_switch/_332', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1/zeros_switch/_144-0-TransposeNHWCToNCHW-LayoutOptimizer' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1/zeros_switch/_144', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/body/_65/sequential_1/conv_lstm2d_1/while/conv_lstm_cell_1/mul' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/body/_65/sequential_1/conv_lstm2d_1/while/conv_lstm_cell_1/add_7'}.\nI0000 00:00:1755660847.679798      75 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778ms/step - accuracy: 0.8416 - auc: 0.6710 - loss: 0.5837","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1755661279.353431      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_76/input/_172' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/body/_76/sequential_1/conv_lstm2d_1_2/while/conv_lstm_cell_1/mul', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/zeros_switch/_99-0-TransposeNHWCToNCHW-LayoutOptimizer' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1_2/zeros_switch/_99', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1/zeros_switch/_56-0-TransposeNHWCToNCHW-LayoutOptimizer' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/StatefulPartitionedCall/sequential_1/conv_lstm2d_1/zeros_switch/_56', 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/body/_33/sequential_1/conv_lstm2d_1/while/conv_lstm_cell_1/mul' -> 'StatefulPartitionedCall/sequential_1/conv_lstm2d_1/while/body/_33/sequential_1/conv_lstm2d_1/while/conv_lstm_cell_1/add_7'}.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_auc improved from -inf to 0.88373, saving model to /kaggle/working/best_convlstm.keras\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 844ms/step - accuracy: 0.8416 - auc: 0.6711 - loss: 0.5837 - val_accuracy: 0.9274 - val_auc: 0.8837 - val_loss: 0.3565\nEpoch 2/50\n\u001b[1m359/547\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 783ms/step - accuracy: 0.8802 - auc: 0.7964 - loss: 0.5315","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}